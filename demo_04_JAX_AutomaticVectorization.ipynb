{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpPJs0qFhVCX"
   },
   "source": [
    "Importing required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "8xOeJIvXErmc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import jit\n",
    "from jax import vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djRtaeCNeSfS"
   },
   "source": [
    "Taking two one dimensional arrays for performing dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "He7xyneAV2dK",
    "outputId": "cd74e495-85b5-4b25-ce01-c3d0dc9160f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,\n",
       "              12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,\n",
       "              24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
       "              36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,\n",
       "              48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,\n",
       "              60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
       "              72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "              84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,\n",
       "              96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "             108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
       "             120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "             132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "             144, 145, 146, 147, 148, 149], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 =  jnp.arange(150)\n",
    "\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QJ4xZEmV9dd",
    "outputId": "4828bfc5-983d-4d3c-bd1e-6cb95d3e1383"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "             112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
       "             124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,\n",
       "             136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
       "             148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n",
       "             160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
       "             172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "             184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "             196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "             208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
       "             220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
       "             232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243,\n",
       "             244, 245, 246, 247, 248, 249], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2 =  jnp.arange(100, 250)\n",
    "\n",
    "array2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZxzkFmFem24"
   },
   "source": [
    "Performing dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alFPnJJGQfbj",
    "outputId": "2aeeae0d-3715-4a67-f688-37698cdf5ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(2231275, dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = jnp.dot(array1, array2)\n",
    "\n",
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxOZus6zIZej",
    "outputId": "1bbc350d-693c-4b07-896c-84c8dbf6f838"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 150), (100, 150))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = jnp.stack([jnp.arange(150) for i in range(100)])\n",
    "array2 = jnp.stack([jnp.arange(100, 250) for i in range(100)])\n",
    "\n",
    "array1.shape, array2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OsBVPF6WGDO"
   },
   "source": [
    "Implementing dot product on a batch of vectors using loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92hVCpC-SBXv",
    "outputId": "f06f1259-a54d-484f-ede7-5cccfdc64277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275]\n",
      "Output shape:  (100,)\n",
      "Time taken in secs 0.9632058143615723\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = []\n",
    "for i in range(100):\n",
    "    output.append(jnp.dot(array1[i], array2[i]))\n",
    "\n",
    "output = jnp.stack(output)\n",
    "print(output)\n",
    "print('Output shape: ', output.shape)\n",
    "\n",
    "time_taken = time.time() - start\n",
    "\n",
    "print('Time taken in secs', time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUCVqfRvaRl8"
   },
   "source": [
    "# Introduction to `vmap`\n",
    "\n",
    "In the above example, you can use the last two operations in JAX as well but we will take a look into a transformation that is literally the best of all. As I said earlier also, this is one of my favorite transformations in JAX - `vmap`\n",
    "\n",
    "## What is `vmap`?\n",
    "`vmap` is just another transformation like jit. It takes a function as an input along with the dimensions for the inputs and the outputs where the functions is to be mapped over to create a vectorized function. The syntax of `vmap` is like this: `vmap(function, in_axes, out_axes, ...)`\n",
    "\n",
    "\n",
    "When you transform a function using `vmap`, it returns a function that is a vectorized version of the original function. Let's see it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ntx8xyYaYiZ",
    "outputId": "5a554bfa-e0a2-4dea-8f0b-8308994d2856"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function jax._src.numpy.lax_numpy.dot>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vmap(jnp.dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdPl5N3whcko"
   },
   "source": [
    "vmap execution seems to be lot faster than looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTanQzgyTszH",
    "outputId": "4fea4433-5a26-4f70-ae05-92a7f52f996d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275]\n",
      "(100,)\n",
      "Time taken in secs 0.09523797035217285\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = vmap(jnp.dot)(array1, array2)\n",
    "\n",
    "print(output)\n",
    "print(output.shape)\n",
    "\n",
    "time_taken = time.time() - start\n",
    "\n",
    "print('Time taken in secs', time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZZq1zYuLKhO"
   },
   "source": [
    "Here `function` is the function that you want to vectorize. `in_axes` is the axis indices that represent the batch dimension in the inputs to the original function. Similarly, `out_axes` are the axis indices that represent the batch dimension in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bew18eqeLFBt",
    "outputId": "5911c1a2-01b1-4239-8890-cee42cddc150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275]\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "output = vmap(jnp.dot, in_axes = (0, 0))(array1, array2)\n",
    "\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJRnes3fErmn"
   },
   "source": [
    "**Note:** Both the arguments necessarily do not need to have a batch dimension. For example, we can take one vector and perform the dot product with a batch of some vectors. For the input that doesn't have a batch dimension, you can just pass `None` in the `in_axes(..)` argument. Let's take an example to make it clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TC46F5wTLUTd",
    "outputId": "7bce5e7c-ee11-4455-bc19-3425bee654cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150,), (100, 150))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = jnp.arange(150)\n",
    "\n",
    "array1.shape, array2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3omzdXZErmn",
    "outputId": "a1fac6c4-b498-4cb4-d082-0f4dd76d75f9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275 2231275\n",
      " 2231275]\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "output = vmap(jnp.dot, in_axes = (None, 0))(array1, array2)\n",
    "\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eklHUAxFiBpM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pujNVaR8Mg7Z"
   },
   "source": [
    "# Batched input to a linear layer\n",
    "\n",
    "- W: weights of a linear layer\n",
    "- batch: Batched input to a linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsNik-3xMuJE",
    "outputId": "a6c566b6-ac97-4815-c235-084d6170b1cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 100), (16, 100))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "W = jax.random.normal(key, (64, 100), dtype = jnp.float32)\n",
    "batch_x = jax.random.normal(key, (16, 100), dtype = jnp.float32)\n",
    "\n",
    "W.shape, batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R4DjmaO9NVH2"
   },
   "outputs": [],
   "source": [
    "def layer(x):\n",
    "  # (64, 100) . (100, ) -> (64, )\n",
    "  return jnp.dot(W, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "yCp_DJnjNbnB",
    "outputId": "77524f2c-4e02-4c04-c144-f73dac7b763f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnfilteredStackTrace\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dbefd067d205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-ab57e7811da8>\u001b[0m in \u001b[0;36mlayer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# (64, 100) . (100, ) -> (64, )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         donated_invars=donated_invars, inline=inline, keep_unused=keep_unused)\n\u001b[0m\u001b[1;32m    526\u001b[0m     \u001b[0mout_pytree_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1836\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1851\u001b[0m   \u001b[0mfun_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    682\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    196\u001b[0m   compiled_fun = xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0;32m--> 197\u001b[0;31m                               keep_unused, *arg_specs)\n\u001b[0m\u001b[1;32m    198\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    245\u001b[0m   return lower_xla_callable(fun, device, backend, name, donated_invars, False,\n\u001b[0;32m--> 246\u001b[0;31m                             keep_unused, *arg_specs).compile().unsafe_call\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mlower_xla_callable\u001b[0;34m(fun, device, backend, name, donated_invars, always_lower, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    290\u001b[0m     jaxpr, out_type, consts = pe.trace_to_jaxpr_final2(\n\u001b[0;32m--> 291\u001b[0;31m         fun, pe.debug_info_final(fun, \"jit\"))\n\u001b[0m\u001b[1;32m    292\u001b[0m   \u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munzip2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_final2\u001b[0;34m(fun, debug_info)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_dynamic2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1960\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_subjaxpr_dynamic2\u001b[0;34m(fun, main)\u001b[0m\n\u001b[1;32m   1919\u001b[0m     \u001b[0min_tracers_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1920\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_tracers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1921\u001b[0m     \u001b[0mout_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   2725\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(lhs, rhs, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m    656\u001b[0m     raise TypeError(\"Incompatible shapes for dot: got {} and {}.\".format(\n\u001b[0;32m--> 657\u001b[0;31m         lhs.shape, rhs.shape))\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnfilteredStackTrace\u001b[0m: TypeError: Incompatible shapes for dot: got (64, 100) and (16, 100).\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dbefd067d205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-ab57e7811da8>\u001b[0m in \u001b[0;36mlayer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# (64, 100) . (100, ) -> (64, )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   2724\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mb_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Incompatible shapes for dot: got (64, 100) and (16, 100)."
     ]
    }
   ],
   "source": [
    "layer(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "veHPiEQCOOHb",
    "outputId": "4684665a-a67e-4f19-b36d-fe0151ee6a4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ -1.3889999 , -20.13941   , -15.254608  ,  12.268584  ,\n",
       "             -11.33385   ,  22.630579  ,   0.6938019 , -13.827613  ,\n",
       "              11.879179  ,  -3.9626598 ,  18.831705  , -14.518444  ,\n",
       "             -10.2607155 , -12.685415  ,   2.5124695 ,  -4.255941  ,\n",
       "              -1.3663094 ,   6.949514  ,  -7.8258133 ,  -8.293367  ,\n",
       "              -6.7460346 , -29.767748  ,  -4.768342  ,  14.712051  ,\n",
       "              -1.9340608 ,   6.222945  ,  13.89996   , -11.409643  ,\n",
       "              -3.2742107 ,  -2.172195  ,  10.826933  ,  -2.5647306 ,\n",
       "              -0.46695018, -11.210756  ,  -7.7417426 , -22.293255  ,\n",
       "               5.421152  ,   1.3914765 ,   3.3206863 ,  -8.409932  ,\n",
       "               2.8698087 ,   7.1217403 ,   3.547274  ,  -4.9375544 ,\n",
       "              -1.4757957 ,  -4.042242  ,  -8.101669  ,   0.17466497,\n",
       "              -3.5307512 ,  -8.768582  ,  14.792691  ,   0.30482912,\n",
       "              20.986172  ,  -0.58729076,   6.2752194 , -20.083494  ,\n",
       "               5.8386536 , -13.792967  , -10.024258  ,   3.3196592 ,\n",
       "              15.8581    ,   5.458009  ,  -6.9915295 ,  27.747955  ],            dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(batch_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bc0ig87cObl7"
   },
   "outputs": [],
   "source": [
    "# Note that this cannot be jitted, because we rely on the content of the input\n",
    "\n",
    "def naive_batched_layer(batch_x):\n",
    "  outputs = []\n",
    "  for row in batch_x:\n",
    "    outputs.append(layer(row))\n",
    "  \n",
    "  return jnp.stack(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqJsPw_lPHQM",
    "outputId": "a072e1d0-c4d7-4c81-8aa9-df96291fc9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive batching\n",
      "The slowest run took 48.71 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 5: 4.14 ms per loop\n"
     ]
    }
   ],
   "source": [
    "print('Naive batching')\n",
    "\n",
    "%timeit naive_batched_layer(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IYp_5hciPOjz"
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def manual_batched_layer(batch_x):\n",
    "  # (16, 100) . (100, 64) -> (16, 64)\n",
    "  return jnp.dot(batch_x, W.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tG1IY0ZvRIuS"
   },
   "source": [
    "# TODO Recording\n",
    "\n",
    "Re-run the cell below 2-3 times to show that the first run takes very long but the subsequent runs are faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qLSNJEXQdV1",
    "outputId": "8f7ed4dc-741d-4f00-949f-44b753f878fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual batching\n",
      "The slowest run took 3154.06 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 5: 8.86 µs per loop\n"
     ]
    }
   ],
   "source": [
    "print('Manual batching')\n",
    "\n",
    "%timeit manual_batched_layer(batch_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f8MTNjJQtff"
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def vmap_batched_layer(batch_x):\n",
    "  return vmap(layer)(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdjbFd1uRg2M",
    "outputId": "d2b6c994-e048-46ca-fc02-efae81ac5f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-vectorized batching\n",
      "The slowest run took 1390.45 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 5: 18.9 µs per loop\n"
     ]
    }
   ],
   "source": [
    "print('Auto-vectorized batching')\n",
    "\n",
    "%timeit vmap_batched_layer(batch_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQsXMVOjRmK1"
   },
   "outputs": [],
   "source": [
    "def layer_with_weights(W, x):\n",
    "  # (64, 100) . (100, ) -> (64, )\n",
    "  return jnp.dot(W, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tn8DvZQTVRwo"
   },
   "source": [
    "# TODO Recording:\n",
    "\n",
    "- first please record with the code which does not have in_axes\n",
    "- Then run the next cell and show the error\n",
    "- Come back to this cell and change the code to have the in_axes\n",
    "- Run the next cell again and show that this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXTw9X2QUa09"
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def vmap_batched_layer_with_weights(W, batch_x):\n",
    "  return vmap(layer_with_weights)(W, batch_x)\n",
    "\n",
    "# def vmap_batched_layer_with_weights(W, batch_x):\n",
    "#   return vmap(layer_with_weights, in_axes = (None, 0))(W, batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PrOmFxJUxVq",
    "outputId": "7733dae7-2c3e-4018-b542-a10c1e6a7069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-vectorized batching\n",
      "The slowest run took 1476.31 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 5: 19.1 µs per loop\n"
     ]
    }
   ],
   "source": [
    "print('Auto-vectorized batching')\n",
    "\n",
    "%timeit vmap_batched_layer_with_weights(W, batch_x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Exl-tLuvU5Fr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "demo_04_AutomaticVectorization.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
