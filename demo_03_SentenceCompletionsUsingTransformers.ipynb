{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGuuxI5oFfgH"
      },
      "source": [
        "### TODO Recording:\n",
        "\n",
        "##### Show HuggingFace\n",
        "\n",
        "- Go to https://huggingface.co/\n",
        "- Click on Models, Datasets, Spaces, Docs on top and show\n",
        "- Back to Models, search for \"gpt2\"\n",
        "- Show the model card"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl7nZh87ZkB4",
        "outputId": "8b3d7a86-158c-4a0f-e385-1ee8c5c6e857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwG0-xF0yoeb"
      },
      "source": [
        "Using pipeline for text generation. By default, it is using GPT2 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pi4FHjmEZj-f"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "text_gen_pl = pipeline(\"text-generation\", model = 'gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "Ovae9ZeM2KkY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7nAakOrzQjd"
      },
      "source": [
        "### Greedy output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        ")\n",
        "\n",
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMG3Gw5ayDzt",
        "outputId": "91b5c8c8-66ab-48c8-9fa0-cfb0c2e94f00"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Today was a hard day at the office but what I realized in that short span of time was that nobody could replace anyone in the room except those who were there and were just doing so to do what happened with the media,\" says Daley.\\n\\n\"It also took a lot of thought, and maybe a little'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence[0][\"generated_text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PS2auzTWyHgo",
        "outputId": "df92c518-9034-4f71-ee26-5732e1e6cdcc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Today was a hard day at the office but what I realized in that short span of time was that nobody could replace anyone in the room except those who were there and were just doing so to do what happened with the media,\" says Daley.\\n\\n\"It also took a lot of thought, and maybe a little'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP1chkzD5H8A",
        "outputId": "1b584f4b-1cae-4366-ac09-d72f1b28e874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office. And, it was a lot of work to do there in the evenings. I had a lot to do. As this project came together, some issues got settled and some things did not. One was the relationship between the board and me in terms of the management and the administration\n",
            "==============================\n",
            "Today was a hard day at the office. The first couple of weeks have been quiet, although one thing is for certain. I am glad this has finally ended. To find out your secrets, I can't help but smile, but, as usual, some people with such a sensitive mind will find it impossible to concentrate\n",
            "==============================\n",
            "Today was a hard day at the office for me so I was happy to be back on record, I will tell you what the experience will be for everyone when I do speak there.\"\n",
            "\n",
            "Theresa May will also speak before the Cabinet later this week.\n",
            "\n",
            "She said: \"We will be speaking to all\n"
          ]
        }
      ],
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    num_return_sequences = 3\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beam Search"
      ],
      "metadata": {
        "id": "C_ptOzXmyf2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    num_beams=2,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF_ejUvH0ZiR",
        "outputId": "f3a53569-df7e-4bea-f2f8-0d4149894cc8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office. We were trying to get things done. We had to start over.\n",
            "\n",
            "\"It was a tough day for us. We had to start over. We had to start over. It's a tough day for me personally, but it's a tough day.\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    num_beams=5,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6z4vIhwybCy",
        "outputId": "00ead893-acb6-498c-bbce-5363a4711af2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office.\n",
            "\n",
            "\"I think it was a good day,\" he said. \"I think it was a good day for the team. I think it was a good day for the organization. I think it was a good day for the players. I think it was a good day\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    num_beams = 5,\n",
        "    no_repeat_ngram_size = 2\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7_F1XZtwu_3",
        "outputId": "5a9ca5b2-aad8-4a56-a47b-2c84debdea9f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office for me. I had to do a lot of things to make sure I was doing everything I could to keep my job and my family together.\n",
            "\n",
            "\"I'm really grateful for the support that I've received over the years, and I'm looking forward to working with the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    num_beams = 5,\n",
        "    no_repeat_ngram_size = 4\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VoW1_Kqx8av",
        "outputId": "14ceae0a-9910-4d93-a799-be2f32b58901"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office.\n",
            "\n",
            "I had no idea what to do.\n",
            "\n",
            "The first thing I did was go to the bathroom.\n",
            "\n",
            "\"What are you doing?\" I asked.\n",
            "\n",
            "He shook his head. \"I don't know.\"\n",
            "\n",
            "I looked at him. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate top beams and pick the best"
      ],
      "metadata": {
        "id": "d-cCikWP0zgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    num_beams = 5,\n",
        "    num_return_sequences=5,\n",
        "    no_repeat_ngram_size = 2\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUwRa4sY0vN0",
        "outputId": "ba4724fe-6928-4242-f8ed-0b2d94d66e3e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office. It was difficult for me to get out of bed, and I was trying to figure out what to do next.\n",
            "\n",
            "\"I was doing a lot of research on what I could do to make sure I wasn't doing something that would get me hurt. I had to\n",
            "==============================\n",
            "Today was a hard day at the office. It was difficult for me to get out of bed, and I was trying to figure out what to do next.\n",
            "\n",
            "\"I was doing a lot of research on what I could do to make sure I wasn't doing something that would get me hurt. I don't\n",
            "==============================\n",
            "Today was a hard day at the office. It was difficult for me to get out of bed, and I was trying to figure out what to do next.\n",
            "\n",
            "\"I was doing a lot of research on what I could do to make sure I wasn't doing something that would get me hurt. I had no\n",
            "==============================\n",
            "Today was a hard day at the office. It was difficult for me to get out of bed, and I was trying to figure out what to do next.\n",
            "\n",
            "\"I was doing a lot of research on what I could do to make sure I wasn't doing something that would get me hurt. I'd been\n",
            "==============================\n",
            "Today was a hard day at the office. It was difficult for me to get out of bed, and I was trying to figure out what to do next.\n",
            "\n",
            "\"I was doing a lot of research on what I could do to make sure I wasn't doing something that would get me hurt. I had some\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling"
      ],
      "metadata": {
        "id": "jpwB4paj2-cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    do_sample = True,\n",
        "    top_k = 0,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d1PWBaD2ujo",
        "outputId": "cfb27eca-c2d1-46b6-9fc8-1c3248556717"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office for Local 6 News. Robert Fraser, the spokesman for Maryland Gov a Democrat denied Howell's activity. He also tapped his son Tim to replace him as chief operating officer. Marci Otefango is the vice president for communications at Desktop TechnologiesUSA. Payne is supervising social\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling with lower temperature makes the output less creative i.e. less random."
      ],
      "metadata": {
        "id": "QP6kfT0m3jx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    do_sample = True,\n",
        "    top_k = 0,\n",
        "    temperature = 0.4,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdS_OlPZ2uf3",
        "outputId": "cc87268d-ebcd-4a08-a286-4767925cc5de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office for me, and I'm looking forward to seeing you again.\"\n",
            "\n",
            "The man who was in charge of the office was a former police officer who had been in the office since 2006.\n",
            "\n",
            "He said the officers had been \"very, very clear\" that they were not\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling with higher temperature generates incomprehensible text"
      ],
      "metadata": {
        "id": "jf72EHXc33W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    do_sample = True,\n",
        "    top_k = 0,\n",
        "    temperature = 1.4,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mvszXM32uXB",
        "outputId": "ddd2a7bb-8584-4014-e143-87187f0bad21"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office. Cigger began street work imagining Stephanie sitting toller on her next dollars gake equally stale bread shake served on what Claude Tokdepth BackType Signature was called Herschel Pellea Eggsahouse Simmons describes as the below all-moons fill taff... so moons mornings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    do_sample = True,\n",
        "    top_k = 3,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDlTVBar2uIR",
        "outputId": "2a9ddece-a097-4656-faf3-e3be664ee2bf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office.\n",
            "\n",
            "\"We're going to be back in a couple of days. I'm going out to dinner and I'm going to get ready for work tomorrow,\" he told the crowd, adding, \"We're going to have to get out of here. I've got a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    do_sample = True,\n",
        "    top_k = 25,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUrwmuRP4bOs",
        "outputId": "283dc628-5827-4ae9-8ddd-d015b58eb2f9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office as I sat in the room with a group of my friends watching us play the new season. The other group was trying to figure out what to do. We were working on a new song and songlist and I didn't want anyone to know the song we were working on.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nulceus sampling"
      ],
      "metadata": {
        "id": "sUQSh-JW5rws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    do_sample = True,\n",
        "    top_p = 0.88,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZuiswP45RlI",
        "outputId": "207ee346-17be-4864-cdc6-2e0231b4f9db"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office for the U.S. Embassy in Beirut, where the three Americans were detained and charged with kidnapping, murder, and other crimes, and a year earlier in Tripoli. We had lost our way, and our men were shot down. It is our hope that the United States will\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    do_sample = True,\n",
        "    top_p = 0.5,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We1S_koo5etJ",
        "outputId": "2e8d309e-7b32-4dad-8b5d-fa09a1b6d7db"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office. I had to make sure I had a nice clean look on my face and I had to keep my eyes on the screen and I had to keep my mouth shut.\n",
            "\n",
            "The day before, I was at the office with my friends and I had a good time. I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling with top-k and top-p"
      ],
      "metadata": {
        "id": "dr0-PIYQ7CO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = text_gen_pl(\n",
        "    \"Today was a hard day at the office\",\n",
        "    max_length = 64,\n",
        "    do_sample = True,\n",
        "    top_k = 30,\n",
        "    top_p = 0.8,\n",
        ")\n",
        "\n",
        "for sentence in sentences:\n",
        "  print(\"=\"*30)\n",
        "  print(sentence[\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq_1iZC97GE3",
        "outputId": "be49e6ee-f1db-470f-db0d-6851ad1c94db"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "Today was a hard day at the office, a tough one, for many of us.\n",
            "\n",
            "And the world's biggest news organizations were all too aware.\n",
            "\n",
            "A new report on CNN revealed that the US government has paid the National Security Agency (NSA) more than $200 million since 2002 to monitor, track\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using a prompt"
      ],
      "metadata": {
        "id": "nFZ2nicD6k2F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTHtJX42F69g"
      },
      "source": [
        "Here we are generating text using a prompt, generating some text related to campaign slogan for car model launch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "0xUCOPCA8N3n"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ows-INKR8Tr_",
        "outputId": "da31e0dc-e9bf-41c7-ca0d-5be3dbdfeb9b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9wia_Sv8Vzw",
        "outputId": "428c70ad-2499-4220-84b7-90ce7abbb235"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.reddit.com/r/KoboldAI/comments/yz26ol/how_to_fix_the_attention_mask_and_the_pad_token/"
      ],
      "metadata": {
        "id": "M6W7G8mo9Mvn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqB4P0MQf1_z",
        "outputId": "5633cbe9-50a3-4ef0-d7d1-631fcab41f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economy has been steadily increasing, with inflation steadily rising and wage growth steadily slowing. It is possible that many Americans still want a job and can be easily lured into one by an increase in living standards. However, the vast majority of Americans have little desire to work. So it is difficult for the government to help them find employment by hiring private contractors.\n",
            "\n",
            "For example, over the past 10 years, U.S. companies have employed more than 10 million people—with nearly 90% of the workers employed by private firms. The percentage of total workers being employed is expected to increase by nearly 20% in 2016. Additionally, as\n"
          ]
        }
      ],
      "source": [
        "# Prompt for text generation\n",
        "prompt = \"The economy\"\n",
        "\n",
        "# Generate text\n",
        "input_ids = tokenizer.encode(prompt, return_tensors = \"pt\")\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length = 128,\n",
        "    num_return_sequences = 1,\n",
        "    no_repeat_ngram_size = 2,\n",
        "    do_sample = True,\n",
        "    top_k = 50,\n",
        "    top_p = 0.92)\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for text generation\n",
        "prompt = \"The economy\"\n",
        "\n",
        "# Generate text\n",
        "input_ids = tokenizer.encode(prompt, return_tensors = \"pt\")\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length = 128,\n",
        "    num_beams = 20,\n",
        "    no_repeat_ngram_size = 1,\n",
        ")\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5EFwihI-E4f",
        "outputId": "39b173cc-6db7-479f-ff59-702d48b5edea"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economy is expected to grow at an annual rate of 2.5 percent this year, the International Monetary Fund (IMF) said in a report released on Friday.\"This growth will be accompanied by strong job creation and higher wages for all workers,\" IMF Director-General Christine Lagarde told reporters as she met with Chinese Premier Li Keqiang during her first official visit abroad since taking over from former President Hu Jintao following his ouster last month\", The Wall Street Journal reported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for text generation\n",
        "prompt = \"The economy\"\n",
        "\n",
        "# Generate text\n",
        "force_words = [\"inflation\"]\n",
        "\n",
        "input_ids = tokenizer.encode(prompt, return_tensors = \"pt\")\n",
        "force_words_ids = tokenizer(force_words, add_special_tokens=False).input_ids\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    force_words_ids = force_words_ids,\n",
        "    max_length = 128,\n",
        "    num_beams = 20,\n",
        "    no_repeat_ngram_size = 1,\n",
        "    remove_invalid_values = True,\n",
        ")\n",
        "\n",
        "# Decode and print the generated text\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens = True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y91HTsVyAP1x",
        "outputId": "18546642-ad05-476a-a6d4-68501d6abf97"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The economy as a whole is growing at an annual rate of 2.5% per annum, according to the Bank for International Settlements (BIS). That's more than double what it was five years ago and nearly three times its pre-recession level in 2008.\"\n",
            "\n",
            "\n",
            "\"Inflation has been rising steadily since 2009,\" he said by phone from New York on Wednesday afternoon after meeting with his counterpart Joseph Stiglitz who will be visiting China this week before taking office next month. \"I think we're seeing some signs that things are getting better but I don't know how much longer they'll stay there orinflation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_xCJyJMSJ1C"
      },
      "source": [
        "Greedy Output generation:We can see repetitions of sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTeUKC0cjikE"
      },
      "source": [
        "Guided Text Generation with Constraints\n",
        "https://huggingface.co/blog/constrained-beam-search#example-2-disjunctive-constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRXre4OVZjBD",
        "outputId": "62a1030d-0190-49d4-b5ac-523596f79d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The cost of the project is estimated to be around $1.5 million.\n",
            "\n",
            "The project will be the first of its kind in the United States, and it is expected to cost between $100 million and $200 million to build. The profits grow\n",
            "The business, which is based in the United States, has been in business for more than a decade.\n",
            "\n",
            "\"We're very pleased to be able to continue to grow our business in a way that is consistent with our commitment to our customers and our profits\n"
          ]
        }
      ],
      "source": [
        "force_word = \"profits\"\n",
        "force_flexible = [\"grow\", \"growth\", \"grew\", \"grown\"]\n",
        "\n",
        "force_words_ids = [\n",
        "    tokenizer([force_word], add_prefix_space = True, add_special_tokens = False).input_ids,\n",
        "    tokenizer(force_flexible, add_prefix_space = True, add_special_tokens = False).input_ids,\n",
        "]\n",
        "\n",
        "starting_text = [\"The cost\", \"The business\"]\n",
        "\n",
        "input_ids = tokenizer(starting_text, return_tensors = \"pt\").input_ids\n",
        "\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    force_words_ids = force_words_ids,\n",
        "    num_beams = 10,\n",
        "    num_return_sequences = 1,\n",
        "    no_repeat_ngram_size = 2,\n",
        "    remove_invalid_values = True,\n",
        "    max_new_tokens =  50,\n",
        "\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens = True))\n",
        "print(tokenizer.decode(outputs[1], skip_special_tokens = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSbwkuuqZiT8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "536HO5kBZiG9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ngTYoRBZiAu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PjrxxHnZh8y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH-I3WVxZh5A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC6AYOJkZh1m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFwwr9Q3Zhy0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTB54kCRZhv1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lPM7OSMZht5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWGgSfgBZhqW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUVY40O_ZhnJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsdi3JaIZhkC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUTKNp-hZg2R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}